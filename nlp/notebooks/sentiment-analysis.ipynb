{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCdKoergjmDw"
   },
   "source": [
    "**Sentiment Analysis on Clothing Reviews**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hBtFjjoqV2_"
   },
   "source": [
    "**Import All Required Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-sSRIdY1HZCS",
    "outputId": "ab15e23e-0924-42bb-c694-f4ddb58df4ef"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUH7jv5KrgG-"
   },
   "source": [
    "**Read data from csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "aBdnYpaqqEfs",
    "outputId": "c4a417df-8a1e-42b2-de17-ed4e672cbbf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Absolutely wonderful silky sexy comfortable</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love dress sooo pretty happened find store im ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love love love jumpsuit fun flirty fabulous ev...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shirt flattering due adjustable front tie perf...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aded basket hte last mintue see would look lik...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  Negative  Neutral  \\\n",
       "0        Absolutely wonderful silky sexy comfortable     False    False   \n",
       "1  Love dress sooo pretty happened find store im ...     False    False   \n",
       "2  love love love jumpsuit fun flirty fabulous ev...     False    False   \n",
       "3  shirt flattering due adjustable front tie perf...     False    False   \n",
       "4  aded basket hte last mintue see would look lik...     False    False   \n",
       "\n",
       "   Positive  \n",
       "0      True  \n",
       "1      True  \n",
       "2      True  \n",
       "3      True  \n",
       "4      True  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('clothing_review_rated.csv')\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O63qBfKuE2nu"
   },
   "source": [
    "**Apply Train Test Split. Add Check Phrases for Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "6PNWLYhME7Pf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16800 7200 16800 7200\n",
      "7203 ['this dress is absolutly gorgeous'\n",
      " 'suit is ugly was made by handless taylor' 'roses were fresh and nice']\n"
     ]
    }
   ],
   "source": [
    "X = df['review'].values\n",
    "y = df.drop('review', axis=1).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))\n",
    "\n",
    "# check phrases fpr later evaluation of results\n",
    "checks = [\"this dress is absolutly gorgeous\", \n",
    "            \"suit is ugly was made by handless taylor\",\n",
    "            \"roses were fresh and nice\"]\n",
    "X_test = np.append(X_test, checks)\n",
    "print(len(X_test), X_test[-3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AuADdT8UFgOy"
   },
   "source": [
    "**Apply vectorization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "r20vXgZ6Fvqw"
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "X_train = vect.fit_transform(X_train)\n",
    "X_test = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "akiDMHsvGNxD"
   },
   "source": [
    "**Apply frequency, inverse document frequency:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "_q3-ppruGRz7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16800 7200 16800 7200\n"
     ]
    }
   ],
   "source": [
    "# create an instance of TfidfTransformer to convert raw term frequencies into TF-IDF scores.\n",
    "tfidf = TfidfTransformer()\n",
    "\n",
    "# fit the transformer to the training data and transform X_train into a TF-IDF weighted matrix.\n",
    "X_train = tfidf.fit_transform(X_train)\n",
    "# transform the test data using the parameters learned from the training data (without refitting).\n",
    "X_test = tfidf.transform(X_test)\n",
    "\n",
    "# convert the sparse matrix of TF-IDF features for the training data into a dense NumPy array.\n",
    "X_train = X_train.toarray()\n",
    "X_test = X_test.toarray()\n",
    "\n",
    "# extract the last 3 rows to remove check phrases from the data\n",
    "X_test_checks = X_test[-3:, :]\n",
    "X_test = X_test[: -3]\n",
    "print(len(X_train), len(X_test), len( y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXV_Xf5kHB73"
   },
   "source": [
    "**Set up the Model: 12680 inputs and 3 outputs for Neg, Pos and Neutral**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "-Su4eu41HAUT"
   },
   "outputs": [],
   "source": [
    "# create an EarlyStopping callback to halt training when the validation loss stops decreasing.\n",
    "# - monitor: the metric to monitor during training; here it's 'val_loss' (validation loss).\n",
    "# - mode: 'min' indicates that training should stop when the monitored metric has stopped decreasing (i.e., we are looking for a minimum).\n",
    "# - verbose: verbosity mode; 1 means that a message is printed when training stops.\n",
    "# - patience: number of epochs to wait after the last time the monitored metric improved before stopping.\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
    "\n",
    "# Dense (fully connected) layer\n",
    "# - units: the number of neurons in the layer (12680 in this case).\n",
    "# - activation: the activation function applied to the output of this layer ('relu' for Rectified Linear Unit).\n",
    "# Dropout layer:\n",
    "# - the parameter (0.5) represents the fraction of the input units to drop during training (helps prevent overfitting).\n",
    "model = Sequential([\n",
    "    Dense(units=12680,activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(units=4000,activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(units=500,activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(units=3, activation='softmax')\n",
    "])\n",
    "\n",
    "opt=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "# compile the model\n",
    "# - loss: 'categorical_crossentropy' is used for multi-class classification problems.\n",
    "# - optimizer: the optimizer instance to use during training, here - Adam.\n",
    "# - metrics: 'accuracy' is used to measure classification accuracy.\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYGn2m1lIFvo"
   },
   "source": [
    "**Fit the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NtKRqIcYIEev",
    "outputId": "0de54d2f-bc01-4606-e290-1f0b216baab5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 1s/step - accuracy: 0.5909 - loss: 0.8033 - val_accuracy: 0.8889 - val_loss: 0.3229\n",
      "Epoch 2/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 1s/step - accuracy: 0.9626 - loss: 0.1177 - val_accuracy: 0.9146 - val_loss: 0.2682\n",
      "Epoch 3/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 1s/step - accuracy: 0.9944 - loss: 0.0216 - val_accuracy: 0.9164 - val_loss: 0.3403\n",
      "Epoch 4/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 1s/step - accuracy: 0.9984 - loss: 0.0065 - val_accuracy: 0.9149 - val_loss: 0.4129\n",
      "Epoch 4: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x26f6df7d1f0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model \n",
    "# x: Input reviews used for training (X_train).\n",
    "# y: Target review labels used for training (y_train).\n",
    "# batch_size: Number of samples per gradient update,256 samples are processed before updating the model.\n",
    "# epochs: The number of complete passes through the training dataset.\n",
    "# validation_data: A tuple (X_test, y_test) used to evaluate the model at the end of each epoch.\n",
    "# verbose: Controls the verbosity of the training output (0,1,2) 1 displays a progress bar and epoch details.\n",
    "# callbacks: List of callback functions to apply during training; here, early_stop will halt training if validation loss stops improving.\n",
    "model.fit(x=X_train, y=y_train, batch_size=256, epochs=100, validation_data=(X_test, y_test), verbose=1, callbacks=early_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mOSbaNrqJBeP"
   },
   "source": [
    "**Evaluation of Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZTsIgolQJD2M",
    "outputId": "a1da4f92-05d5-46d3-d8fe-f2c1424747eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - accuracy: 0.9176 - loss: 0.4036\n",
      "Test accuracy: 0.9148610830307007\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "this dress is absolutly gorgeous \t: 2\n",
      "suit is ugly was made by handless taylor \t: 0\n",
      "roses were fresh and nice \t: 2\n"
     ]
    }
   ],
   "source": [
    "model_score = model.evaluate(X_test, y_test, batch_size=64, verbose=1)\n",
    "print('Test accuracy:', model_score[1])\n",
    "\n",
    "# reviews on which we need to predict\n",
    "pred = model.predict(X_test_checks)\n",
    "pred = np.array([np.argmax(i) for i in pred])\n",
    "for i in range(len(checks)):\n",
    "    print(checks[i], '\\t:', pred[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
